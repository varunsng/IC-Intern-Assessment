# -*- coding: utf-8 -*-
"""IC Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XA53joBfYuL8JPdslQ_imJCVN5MsatmI
"""

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive/')

import librosa
audio_path = '/content/drive/MyDrive/audio dataset/Actor_01/03-01-01-01-01-01-01.wav'
x,sr = librosa.load(audio_path)

import IPython.display as ipd
ipd.Audio(audio_path)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import sklearn
import matplotlib.pyplot as plt
import librosa.display
plt.figure()
librosa.display.waveplot(x,sr)

mfccs = librosa.feature.mfcc(x, sr=sr)
print(mfccs.shape)

librosa.display.specshow(mfccs, sr=sr, x_axis='time')

"""Female is identified as '2', while male is identified as '1'"""

def gender(g):
  if int(g[0:2])%2==0:
      return 2
  else:
      return 1

"""Using the MFCC feature extraction"""

def extract_feature(file_name):
    X, sample_rate = librosa.load(file_name)
    stft=np.abs(librosa.stft(X))
    result=np.array([])
    mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)
    result=np.hstack((result, mfccs))
    return result

"""Going through each file in the dataset and extracting the feature and the corresponding gender label"""

import os
import numpy as np
path = '/content/drive/My Drive/audio dataset'
a = []
for subdir, dirs, files in os.walk(path):
  for file in files:
    try:
      X,sr = librosa.load(os.path.join(subdir,file),res_type='kaiser_fast')
      mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sr,n_mfcc=40).T,axis = 0)
      emotion = gender(file.split('-')[-1])
      arr = mfccs, emotion
      a.append(arr)
    except ValueError:
      continue

x, y = zip(*a)
x = np.asarray(x)
y = np.asarray(y)
x.shape, y.shape

print(x[0],y[284])

import sklearn
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.20,random_state=42)

"""MLP Model

using sigmoid activation function and using dropouts to improve the accuracy
"""

import tensorflow as tf
model=tf.keras.models.Sequential([
   tf.keras.layers.Flatten(),                                                                
   tf.keras.layers.Dense(7200,activation='sigmoid',input_shape=(40,1)),                                                                
   tf.keras.layers.Dense(1024,activation='sigmoid'),
   tf.keras.layers.Dropout(0.2),
   tf.keras.layers.Dense(256,activation='sigmoid'),
   tf.keras.layers.Dropout(0.45),                          
   tf.keras.layers.Dense(3,activation='softmax'),
   ])

"""To plot the accuracy vs epoch graph"""

def plot_history(history):
    plt.plot(history.history['accuracy'], label='accuracy')
    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(loc='lower right')

model.compile(optimizer='rmsprop',loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=50,
                   validation_data=(x_test, y_test))

plot_history(history)

model.evaluate(x_test,y_test)

"""LSTM model
Using Batch Normalisation and applying dropouts
"""

import tensorflow as tf
import keras
model_lstm = tf.keras.models.Sequential([tf.keras.layers.BatchNormalization(),
                             tf.keras.layers.LSTM(units = 256, dropout=0.1,recurrent_dropout=0.2,activation='tanh',input_shape=(40,1),return_sequences=True),
                             tf.keras.layers.Flatten(),
                             tf.keras.layers.Dense(64,activation='relu'),
                             tf.keras.layers.Dense(3, activation='softmax')])

model_lstm.compile(optimizer='rmsprop',loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])

"""Expanding the dimensions of my test and train array"""

x_train_new = np.expand_dims(x_train,axis=2)
x_test_new = np.expand_dims(x_test,axis=2)
x_train_new.shape, x_test_new.shape

model_lstm_history = model_lstm.fit(x_train_new,y_train,batch_size=32,epochs=50,validation_data=(x_test_new,y_test))

model_lstm.evaluate(x_test_new,y_test)

plt.plot(model_lstm_history.history['accuracy'])
plt.plot(model_lstm_history.history['val_accuracy'])
plt.title('model acc')
plt.ylabel('acc')
plt.xlabel('epochs')